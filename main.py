# -*- coding: utf-8 -*-

import os
import numpy as np
from scipy import io as sio
import pickle
import argparse
from termcolor import cprint

import torch
import torch.nn as nn
import torch.utils.data as data
import torch.nn.functional as F
import torch.autograd as autograd
from torch.autograd import Variable
from torch.utils.data import Dataset
from torchvision import transforms
import torch.nn.init as init

from data_utils import ZSL_Dataset
from models import _netG, _netG2, _netD, Regressor, _netQ
import kNN
import kNN_cosine
from ksvm import MyKSVM
from debug import visualization
from classifiers import SoftmaxClassifier
from common_tools import print_args, nets_weights_init, reset_grad, print_nets, cosine_distance_numpy, cosine_distance_tensor
from utils import NormalNLLLoss


def arg_parse():
    desc = 'deep embedding model for zero-shot video classification'
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('--mode', type=str, default='train', help='train or test')
    parser.add_argument('--dataset_name', type=str, default='cub', help='dataset name')
    parser.add_argument('--resume', type=str, default='', help='path of checkpoint file for restarting or testing')
    parser.add_argument('--n_iteration', type=int, default=10, help='how many iteration to run')
    parser.add_argument('--batch_size', type=int, default=64, help='batch size')
    parser.add_argument('--lr_G', type=float, default=1e-4, help='learning rate of G')
    parser.add_argument('--lr_D', type=float, default=1e-4, help='learning rate of D')
    parser.add_argument('--lr_R', type=float, default=1e-4, help='learning rate of R')
    parser.add_argument('--weight_decay', type=float, default=1e-2, help='weight decay')
    parser.add_argument('--optimizer', type=str, default='adam', help='which optimizer to use')
    parser.add_argument('--labelIdxStart0or1', type=int, choices=[0, 1], default=1, help='self explained')
    parser.add_argument('--root_dir', type=str, default='/media/sdb1/chenrui/journal/zeroshot/relatedwork/LearningToCompare_ZSL/data', help='root dir of data')
    parser.add_argument('--save_dir', type=str, default='./checkpoint', help='root dir for saving model')
    parser.add_argument('--all_visualFea_label_file', type=str, default='res101.mat', help='file contains both visual feature and label of whole datset')
    parser.add_argument('--auxiliary_file', type=str, default='att_splits.mat', help='file contains splits and semantic feature')
    parser.add_argument('--use_z', type=str, default='true', help='use noise z or not')
    parser.add_argument('--z_dim', type=int, default=100, help='dimension of noise')
    parser.add_argument('--gpuid', type=int, default=0, help='which gpu to use')
    parser.add_argument('--centroid_lambda', type=float, default=1., help='hyperparameter of centroid loss')
    parser.add_argument('--_lambda', type=float, default=0.00015, help='TODO')
    parser.add_argument('--gp_lambda', type=float, default=1., help='hyperparameter of gradient penalty')
    parser.add_argument('--regression_lambda', type=float, default=1., help='hyperparameter of semantic feature regression')
    parser.add_argument('--n_iter_D', type=int, default=5, help='iteration number of D')
    parser.add_argument('--n_iter_G', type=int, default=1, help='iteration number of G')
    parser.add_argument('--n_generation_perClass', type=int, default=50, help='how many samples will be generated by G for SVM training')
    parser.add_argument('--classifier_type', type=str, default='knn', help='what kind of classifier to use for the final unseen classification task. (e.g., knn, svm)')
    parser.add_argument('--n_epoch_sftcls', type=int, default=10, help='epochs for softmax classifier training')
    parser.add_argument('--use_pca', type=str, default='true', help='use PCA (for visual feature) or not')
    parser.add_argument('--reduced_dim_pca', type=int, default=1024, help='the dimension of visual feature after PCA')
    parser.add_argument('--miu', type=float, default=1.2, help='for "adaptive outlier detection"')
    parser.add_argument('--od_lambda', type=float, default=0.05, help='the trade-off hyperparameter for cosine loss in "adaptive outlier detection"')
    parser.add_argument('--use_od', type=str, default='false', help='whether to use "adaptive outlier detection" (default is false for effectiveness)')
    parser.add_argument('--MI_lambda', type=float, default=0.01, help='the trade-off hyperparameter for mutual information loss')
    
    args = parser.parse_args()
    return args


def calc_gradient_penalty(netD, real_data, fake_data, args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    alpha = torch.rand(real_data.size()[0], 1)
    alpha = alpha.expand(real_data.size())
    alpha = alpha.to(device)

    interpolates = alpha * real_data + ((1 - alpha) * fake_data)
    interpolates = interpolates.to(device)
    interpolates = Variable(interpolates, requires_grad=True)
    _, disc_interpolates, _ = netD(interpolates)

    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,
                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),
                              create_graph=True, retain_graph=True, only_inputs=True)[0]
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * args.gp_lambda
    return gradient_penalty


def getloss(syn_vi_fea, real_vi_fea):
    loss = torch.pow(real_vi_fea - syn_vi_fea, 2).sum()
    loss /= real_vi_fea.size(0)
    return loss


def getloss_cosine(syn_vi_fea, real_vi_fea):
    assert syn_vi_fea.size(0) == real_vi_fea.size(0)
    batch_size = syn_vi_fea.size(0)
    loss = 0.
    for i in range(batch_size):
        v1_sq = torch.dot(syn_vi_fea[i, :], syn_vi_fea[i, :])
        v2_sq = torch.dot(real_vi_fea[i, :], real_vi_fea[i, :])
        dis = 1 - torch.dot(syn_vi_fea[i, :], real_vi_fea[i, :]) / (v1_sq * v2_sq).sqrt()
        loss += dis
    return loss


def compute_accuracy(generator, test_semantic, test_visual, test_classIdx, test_videoLabel, use_z, n_gene_perC, classifier_type, n_epoch_sftcls):
    '''evaluation'''
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    n_generation_perClass = n_gene_perC    # how many samples are generated by G per class
    nb_samples = test_visual.shape[0]
    test_semantic = torch.from_numpy(test_semantic).float().to(device)
    if use_z == 'true':
        z = torch.randn(test_semantic.size()[0], z_dim).to(device)
        syn_vi_fea = generator(test_semantic, z)
    else:
        syn_vi_fea = generator(test_semantic)
    
    ## kNN as a classifier during testing
    if classifier_type == 'knn':
        outpred = [0] * nb_samples
        test_videoLabel = test_videoLabel.astype("float32")

        '''
            syn_vi_fea : [nb_testClass, vi_fea_dim] e.g., [50, 8192],
            test_visual: [nb_samples, 1024]
            test_id    : [nb_testClass] e.g., 50 in ucf101 51/50 setting.
        '''
        for i in range(nb_samples):
            outputLabel = kNN.kNNClassify(test_visual[i, :], syn_vi_fea.cpu().data.numpy(), test_classIdx, 5)
            outpred[i] = outputLabel
        outpred = np.array(outpred)
        acc = np.equal(outpred, test_videoLabel).mean()

    ## kernel svm as a classifier during testing
    elif classifier_type == 'svm' or 'softmax':
        expend_testvideoLabel = test_classIdx
        for cnt in range(n_generation_perClass - 1):
            if use_z == 'true':
                z = torch.randn(test_semantic.size()[0], z_dim).to(device)
                temp_syn_vi_fea = generator(test_semantic, z)
            else:
                temp_syn_vi_fea = generator(test_semantic)
            syn_vi_fea = torch.cat((syn_vi_fea, temp_syn_vi_fea), dim=0)
            expend_testvideoLabel = np.hstack((expend_testvideoLabel, test_classIdx))

        assert syn_vi_fea.size(0) == expend_testvideoLabel.shape[0]
        syn_vi_fea = syn_vi_fea.cpu().detach().numpy()

        dataset_obj = dict()
        dataset_obj['tr_data' ] = syn_vi_fea
        dataset_obj['tr_label'] = expend_testvideoLabel
        dataset_obj['te_data' ] = test_visual
        dataset_obj['te_label'] = test_videoLabel
        if classifier_type == 'svm':
            ksvm = MyKSVM(dataset_obj)
            acc1 = ksvm.linear_kernel()
            acc2 = ksvm.nonlinear_kernel()     # if degree == 3, may raise a MemoryError
            acc3 = ksvm.poly_kernel()
            acc4 = ksvm.RBF_kernel()
            acc  = max((acc1, acc2, acc3, acc4))
        elif classifier_type == 'softmax':
            n_class = len(test_classIdx)
            n_epoch = n_epoch_sftcls
            batch_size = -1
            lr = 1e-3
            sft_cls = fit_softmaxClassifier(n_class, dataset_obj, n_epoch, batch_size, lr)
            te_y = dataset_obj['te_label']
            global_label = set(te_y)
            globalLabel2localLabel = dict()
            for global_idx, local_idx in zip(global_label, list(range(len(global_label)))):
                globalLabel2localLabel[global_idx] = local_idx
            te_y = np.array([globalLabel2localLabel[i] for i in te_y])
            te_x = torch.from_numpy(dataset_obj['te_data']).float()
            te_y = torch.from_numpy(te_y).long()
            sft_cls.cpu()
            te_y_hat = sft_cls(te_x)
            acc = (np.argmax(te_y_hat.detach().numpy(), axis=1) == te_y.detach().numpy()).sum() / float(te_y.size()[0])

    return acc



def fit_softmaxClassifier(n_class, dataset_dict, n_epoch, batch_size, lr):
    '''fit softmax classifier by generated visual feature for performance evaluation.'''
    tr_x = dataset_dict['tr_data' ]
    tr_y = dataset_dict['tr_label']

    input_dim = tr_x.shape[-1]
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    sft_cls = SoftmaxClassifier(input_dim, n_class).to(device)
    nets_weights_init((sft_cls,))
    sft_cls.train()
    
    optimizer = torch.optim.Adam(sft_cls.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    global_label = set(tr_y)
    globalLabel2localLabel = dict()
    for global_idx, local_idx in zip(global_label, list(range(len(global_label)))):
        globalLabel2localLabel[global_idx] = local_idx
    tr_y = np.array([globalLabel2localLabel[i] for i in tr_y])
    tr_x = torch.from_numpy(tr_x).to(device).float()
    tr_y = torch.from_numpy(tr_y).to(device).long()
    for e in range(n_epoch):
        tr_y_hat = sft_cls(tr_x)
        loss = criterion(tr_y_hat, tr_y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        tr_acc = (np.argmax(tr_y_hat.detach().cpu().numpy(), axis=1) == tr_y.detach().cpu().numpy()).sum() / float(tr_y.size()[0])

    return sft_cls


if __name__ == '__main__':
    args = arg_parse()
    print_args(args)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpuid)
    mode = args.mode
    dataset_name = args.dataset_name
    labelIdxStart0or1 = args.labelIdxStart0or1
    root_dir = args.root_dir
    all_visualFea_label_file = args.all_visualFea_label_file
    auxiliary_file = args.auxiliary_file
    batch_size = args.batch_size
    lr_G = args.lr_G
    lr_D = args.lr_D
    lr_R = args.lr_R
    weight_decay = args.weight_decay
    n_iter_D = args.n_iter_D
    n_iter_G = args.n_iter_G
    use_pca = args.use_pca
    reduced_dim_pca = args.reduced_dim_pca

    zsl_dataset = ZSL_Dataset(root_dir, dataset_name, mode, all_visualFea_label_file, auxiliary_file, use_pca, reduced_dim_pca)
    zsl_dataloader = data.DataLoader(zsl_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    print('data is ready!')

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    vi_fea_dim = zsl_dataset.vis_fea_dim
    se_fea_dim = zsl_dataset.sem_fea_dim
    n_tr_class = zsl_dataset.n_tr_class
    z_dim = args.z_dim
    if args.use_z.lower() == 'true':
        netG = _netG(se_fea_dim, vi_fea_dim, z_dim).to(device)
    else:
        netG = _netG2(se_fea_dim, vi_fea_dim).to(device)
    netD = _netD(vi_fea_dim, n_tr_class).to(device)
    netR = Regressor(vi_fea_dim, se_fea_dim).to(device)
    netQ = _netQ(input_dim=1024).to(device)
    nets = [netG, netD, netR, netQ]
    nets_weights_init(nets)
    print_nets(nets)

    te_data_unseen, te_data_seen = zsl_dataset.get_testData()
    te_vis_fea_unseen, te_sem_fea_unseen, te_label_unseen, te_labelID_unseen, te_sem_fea_pro_unseen = te_data_unseen
    te_vis_fea_seen, te_sem_fea_seen, te_label_seen, te_labelID_seen, te_sem_fea_pro_seen = te_data_seen
    tr_vis_fea, tr_sem_fea, all_tr_label, tr_labelID, tr_sem_fea_pro = zsl_dataset.get_trainData()

    tr_cls_centroid = zsl_dataset.get_tr_centroid()
    tr_cls_centroid = torch.from_numpy(tr_cls_centroid).to(device)

    which_optimizer = args.optimizer.lower()
    assert which_optimizer in ['adam', 'sgd', 'rmsprop']
    if  which_optimizer == 'adam':
        optimizer_G = torch.optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=lr_G, weight_decay=weight_decay)
        optimizer_D = torch.optim.Adam(netD.parameters(), lr=lr_D, weight_decay=weight_decay)
        optimizer_R = torch.optim.Adam(netR.parameters(), lr=lr_R, weight_decay=weight_decay)
    elif which_optimizer == 'sgd':
        optimizer_G = torch.optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=lr_G, weight_decay=weight_decay)
        optimizer_D = torch.optim.SGD(netD.parameters(), lr=lr_D, weight_decay=weight_decay)
        optimizer_R = torch.optim.SGD(netR.parameters(), lr=lr_R, weight_decay=weight_decay)
    elif which_optimizer == 'rmsprop':
        optimizer_G = torch.optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=lr_G, weight_decay=weight_decay)
        optimizer_D = torch.optim.RMSprop(netD.parameters(), lr=lr_D, weight_decay=weight_decay)
        optimizer_R = torch.optim.RMSprop(netR.parameters(), lr=lr_R, weight_decay=weight_decay)


    # regression_criterion = nn.MSELoss()
    regression_criterion = nn.L1Loss()
    Q_criterion = NormalNLLLoss()

    save_subdir = dataset_name
    save_dir = os.path.join(args.save_dir, save_subdir)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    best_acc_unseen = 0
    best_acc_seen = 0
    data_iterator = enumerate(zsl_dataloader)
    for i in range(args.n_iteration):
        '''updata discriminator'''
        for _ in range(n_iter_D):
            try:
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)
            except StopIteration:
                data_iterator = enumerate(zsl_dataloader)
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)

            X_real = vi_fea.to(device)
            se_fea = se_fea.to(device)
            y_true = tr_label.to(device)
            z = torch.randn(se_fea.size()[0], z_dim).to(device)

            reset_grad(nets)

            ## GAN's D loss
            _, D_real, C_real = netD(X_real)     # `C` here means `classification`
            D_loss_real = torch.mean(D_real)
            C_loss_real = F.cross_entropy(C_real, y_true)
            DC_loss = -D_loss_real + C_loss_real
            DC_loss.backward(retain_graph=True)     # for `Wasserstein_D.backward()` below.

            ## GAN's G loss
            if args.use_z.lower() == 'true':
                X_fake = netG(se_fea, z)
            else:
                X_fake = netG(se_fea)
            _, D_fake, C_fake = netD(X_fake)
            D_loss_fake = torch.mean(D_fake)
            C_loss_fake = F.cross_entropy(C_fake, y_true)
            DC_loss = D_loss_fake + C_loss_fake
            DC_loss.backward(retain_graph=True)

            ## train with gradient penalty (WGAN_GP)
            grad_penalty = calc_gradient_penalty(netD, X_real.data, X_fake.data, args)
            grad_penalty.backward()
            Wasserstein_D = D_loss_real - D_loss_fake
            Wasserstein_D.backward()    # zcr
            optimizer_D.step()

        '''update generator'''
        for _ in range(n_iter_G):
            try:
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)
            except StopIteration:
                data_iterator = enumerate(zsl_dataloader)
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)

            X_real = vi_fea.to(device)
            se_fea = se_fea.to(device)
            y_true = tr_label.to(device)
            z = torch.randn(se_fea.size()[0], z_dim).to(device)   # the last batch will be not equal to the batchsize, thus use `se_fea.size()[0]` rather than `batchsize`

            if args.use_z.lower() == 'true':
                X_fake = netG(se_fea, z)
            else:
                X_fake = netG(se_fea)
            D_shared, D_fake, C_fake = netD(X_fake)
            _, __, C_real = netD(X_real)

            ## GAN's G loss
            G_loss = torch.mean(D_fake)
            ## Auxiliary classification loss
            C_loss = (F.cross_entropy(C_real, y_true) + F.cross_entropy(C_fake, y_true)) / 2
            
            GC_loss = -G_loss + C_loss

            ## mutual information loss
            q_mu, q_var = netQ(D_shared)
            MI_loss = Q_criterion(se_fea, q_mu, q_var) * args.MI_lambda

            ## centroid loss
            centroid_loss = torch.FloatTensor([0.0]).to(device)
            for j in range(n_tr_class):
                current_tr_classIdx = zsl_dataset.tr_classIdx_map[zsl_dataset.tr_labelID[j]]
                sample_idx = (y_true == current_tr_classIdx).data.nonzero().squeeze()   # get the index of the current training class
                if sample_idx.numel() != 0:
                    fake_sample_of_current_class = X_fake[sample_idx, :]
                    centroid_loss += (fake_sample_of_current_class.mean(dim=0) - tr_cls_centroid[j]).pow(2).sum().sqrt()
            centroid_loss *= 1.0 / n_tr_class * args.centroid_lambda
            

            ## semantic feature regression loss
            fake_semantic_regression = netR(X_fake)
            assert fake_semantic_regression.size() == se_fea.size()
            regrs_loss = regression_criterion(fake_semantic_regression, se_fea) * args.regression_lambda


            ## `adaptive outlier detection`
            cosine_loss = 0.0
            if args.use_z.lower() == 'true' and args.use_od == 'true':
                cprint('*' * 100, 'red')
                original_n_se_fea = se_fea.size(0)  # original number of the semantic features
                _n_noise = 5
                n_noise = se_fea.size()[0] * _n_noise
                z = torch.randn(n_noise, z_dim).to(device)
                repeat_se_fea = se_fea.repeat((_n_noise, 1))    # repeat in rows
                _X_fake = netG(repeat_se_fea, z)
                _fake_semantic_regression = netR(_X_fake)
                batch_cosine_buffer = []
                for _i in range(original_n_se_fea):
                    _index = [_i + original_n_se_fea * j for j in range(_n_noise)]
                    _index = torch.from_numpy(np.array(_index)).to(device)
                    current_se_fake = _fake_semantic_regression[_index]
                    assert current_se_fake.size(0) == _n_noise
                    instance_cosine_buffer = []
                    for k in range(_n_noise):
                        instance_cosine_buffer.append(cosine_distance_tensor(current_se_fake[k, :], se_fea[_i, :]))
                    _delta = max(instance_cosine_buffer) - min(instance_cosine_buffer)
                    _eta = min(instance_cosine_buffer) + args.miu * _delta
                    _cosine_buffer = [c for c in instance_cosine_buffer if c < _eta]
                    batch_cosine_buffer.append(sum(_cosine_buffer))
                cosine_loss = sum(batch_cosine_buffer) / _n_noise
                cosine_loss *= args.od_lambda

            loss1 = getloss(X_fake, X_real)
            loss2 = getloss_cosine(X_fake, X_real)
            _loss = args._lambda * loss1 + loss2

            reset_grad(nets)

            total_loss = GC_loss + centroid_loss + _loss + regrs_loss
            # total_loss = GC_loss + centroid_loss + _loss + regrs_loss + cosine_loss + MI_loss

            total_loss.backward()

            optimizer_G.step()
            optimizer_R.step()

        if i % 10 == 0 and i != 0:
            acc_real = (np.argmax(C_real.data.cpu().numpy(), axis=1) == y_true.data.cpu().numpy()).sum() / float(y_true.data.size()[0])
            acc_fake = (np.argmax(C_fake.data.cpu().numpy(), axis=1) == y_true.data.cpu().numpy()).sum() / float(y_true.data.size()[0])

            if acc_fake > 0.:
                unseen_acc = 100 * compute_accuracy(netG, te_sem_fea_pro_unseen, te_vis_fea_unseen, te_labelID_unseen, te_label_unseen, args.use_z.lower(), args.n_generation_perClass, args.classifier_type, args.n_epoch_sftcls)
                seen_acc = 100 * compute_accuracy(netG, te_sem_fea_pro_seen, te_vis_fea_seen, te_labelID_seen, te_label_seen, args.use_z.lower(), args.n_generation_perClass, args.classifier_type, args.n_epoch_sftcls)
            else:
                unseen_acc = -1
                seen_acc = -1
                acc_tr = -1

            print('It%5d  Was_D:%6.2lf  cen_ls:%5.2lf  rgs_ls:%5.3lf  G_ls:%6.3lf  C_ls:%5.3lf  D_ls_real:%6.3lf  C_ls_real:%5.3lf  D_ls_fake:%6.3lf  C_ls_fake:%5.3lf  _ls:%6.3lf  tr_real_a:%4.2lf tr_fake_a:%4.2lf uns_a: %.2lf  s_a: %.2lf  a_tr: %.2lf' \
                  % (i, Wasserstein_D.item(), centroid_loss.item(), args.regression_lambda * regrs_loss.item(), G_loss.item(), C_loss.item(), D_loss_real.item(), C_loss_real.item(), D_loss_fake.item(), C_loss_fake.item(), _loss.item(), acc_real, acc_fake, unseen_acc, seen_acc, acc_tr))

            if unseen_acc > best_acc_unseen:    # save model based on the accuracy of unseen class.
                best_acc_unseen = unseen_acc
                save_dict = {
                    'iteration': (i + 1),
                    'netG_state_dict': netG.state_dict(),
                    'netD_state_dict': netD.state_dict(),
                    'netR_state_dict': netR.state_dict(),
                    'acc_unseen': best_acc_unseen,
                    'acc_seen': seen_acc,
                }
                checkpoint_name = 'checkpoint_' + dataset_name + '_iter' + str(i + 1) + '_accUnseen%.2lf_accSeen%.2lf.pkl' % (best_acc_unseen, acc_seen)
                checkpoint_path = os.path.join(save_dir, checkpoint_name)
                cprint('saving ' + checkpoint_name + ' in ' + save_dir + '...', 'green')
                torch.save(save_dict, checkpoint_path)